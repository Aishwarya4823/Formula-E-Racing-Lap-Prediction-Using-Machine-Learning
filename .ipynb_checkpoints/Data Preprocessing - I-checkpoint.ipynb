{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', None)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# pd.set_option('max_colwidth',-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting and concatenating all csv files per year\n",
    "path_folder = \"./sampledata/\"\n",
    "folder_list = os.listdir(\"./sampledata\")\n",
    "EXT = \"*.csv\"\n",
    "for sub in folder_list[:1]:\n",
    "    PATH = path_folder + sub\n",
    "    all_csv_files = [file \n",
    "                     for path, subdir, files in os.walk(PATH)\n",
    "                     for file in glob(os.path.join(path,EXT))\n",
    "                    ]\n",
    "    df = pd.concat((pd.read_csv(f, sep=\";\", encoding = \"ISO-8859-1\").assign(file_loc=f) for f in all_csv_files))\n",
    "\n",
    "    df = df.rename(columns=lambda x: x.strip())\n",
    "    df.to_csv('./cleaned/' + sub + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 25', 'DRIVER_HOMETOWN', 'FL_TIME', 'ï»¿NUMBER',\n",
       "       'S2_IMPROVEMENT', 'KPH', 'LAPS', 'ï»¿POSITION', 'FL_LAPNUM',\n",
       "       'DRIVER_FIRSTNAME', 'ELAPSED', 'MANUFACTURER', 'S1_LARGE', 'PIT_TIME',\n",
       "       'DRIVER_NAME', 'S3_LARGE', 'HOUR', 'file_loc', 'FL_KPH', 'S3', 'TEAM',\n",
       "       'LAP_TIME', 'DRIVER_LICENSE', 'NUMBER', 'TOTAL_TIME', 'S1_IMPROVEMENT',\n",
       "       'S1', 'DIVISION', 'GAP_FIRST', 'GAP_PREVIOUS', 'CLASS', 'TOP_SPEED',\n",
       "       'STATUS', 'DRIVER_SHORTNAME', 'DRIVER_COUNTRY', 'S2', 'S2_LARGE',\n",
       "       'LAP_IMPROVEMENT', 'DRIVER_NUMBER', 'S3_IMPROVEMENT', 'LAP_NUMBER',\n",
       "       'CROSSING_FINISH_LINE_IN_PIT', 'GROUP', 'TIRES', 'VEHICLE',\n",
       "       'DRIVER_SECONDNAME'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74012, 46)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>ï»¿NUMBER</th>\n",
       "      <th>S2_IMPROVEMENT</th>\n",
       "      <th>KPH</th>\n",
       "      <th>LAPS</th>\n",
       "      <th>ï»¿POSITION</th>\n",
       "      <th>FL_LAPNUM</th>\n",
       "      <th>FL_KPH</th>\n",
       "      <th>DRIVER_LICENSE</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>S1_IMPROVEMENT</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>TOP_SPEED</th>\n",
       "      <th>DRIVER_SHORTNAME</th>\n",
       "      <th>LAP_IMPROVEMENT</th>\n",
       "      <th>DRIVER_NUMBER</th>\n",
       "      <th>S3_IMPROVEMENT</th>\n",
       "      <th>LAP_NUMBER</th>\n",
       "      <th>TIRES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>67388.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.287118</td>\n",
       "      <td>0.112343</td>\n",
       "      <td>101.683755</td>\n",
       "      <td>30.704545</td>\n",
       "      <td>8.823204</td>\n",
       "      <td>23.259091</td>\n",
       "      <td>116.272350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>0.086784</td>\n",
       "      <td>0.113454</td>\n",
       "      <td>14.656467</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.259728</td>\n",
       "      <td>0.479707</td>\n",
       "      <td>25.887216</td>\n",
       "      <td>8.970727</td>\n",
       "      <td>4.913893</td>\n",
       "      <td>8.467028</td>\n",
       "      <td>6.986659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.621204</td>\n",
       "      <td>0.476026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481071</td>\n",
       "      <td>0.281521</td>\n",
       "      <td>0.481729</td>\n",
       "      <td>10.927544</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>112.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.400000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>115.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>119.900000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>184.500000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>130.100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 25     ï»¿NUMBER  S2_IMPROVEMENT           KPH        LAPS  \\\n",
       "count          0.0  73792.000000    73792.000000  67388.000000  220.000000   \n",
       "mean           NaN     24.287118        0.112343    101.683755   30.704545   \n",
       "std            NaN     24.259728        0.479707     25.887216    8.970727   \n",
       "min            NaN      1.000000        0.000000      1.700000    0.000000   \n",
       "25%            NaN      7.000000        0.000000    100.200000   29.000000   \n",
       "50%            NaN     19.000000        0.000000    109.400000   31.000000   \n",
       "75%            NaN     28.000000        0.000000    116.000000   35.000000   \n",
       "max            NaN     99.000000        4.000000    184.500000   47.000000   \n",
       "\n",
       "       ï»¿POSITION   FL_LAPNUM      FL_KPH  DRIVER_LICENSE      NUMBER  \\\n",
       "count   181.000000  220.000000  217.000000             0.0  220.000000   \n",
       "mean      8.823204   23.259091  116.272350             NaN   29.650000   \n",
       "std       4.913893    8.467028    6.986659             NaN   29.621204   \n",
       "min       1.000000    0.000000  102.100000             NaN    2.000000   \n",
       "25%       5.000000   20.000000  112.700000             NaN    7.750000   \n",
       "50%       9.000000   25.000000  115.800000             NaN   19.500000   \n",
       "75%      13.000000   29.000000  119.900000             NaN   36.250000   \n",
       "max      19.000000   47.000000  130.100000             NaN   99.000000   \n",
       "\n",
       "       S1_IMPROVEMENT  DIVISION  CLASS  TOP_SPEED  DRIVER_SHORTNAME  \\\n",
       "count    73792.000000       0.0    0.0        0.0               0.0   \n",
       "mean         0.110432       NaN    NaN        NaN               NaN   \n",
       "std          0.476026       NaN    NaN        NaN               NaN   \n",
       "min          0.000000       NaN    NaN        NaN               NaN   \n",
       "25%          0.000000       NaN    NaN        NaN               NaN   \n",
       "50%          0.000000       NaN    NaN        NaN               NaN   \n",
       "75%          0.000000       NaN    NaN        NaN               NaN   \n",
       "max          4.000000       NaN    NaN        NaN               NaN   \n",
       "\n",
       "       LAP_IMPROVEMENT  DRIVER_NUMBER  S3_IMPROVEMENT    LAP_NUMBER  TIRES  \n",
       "count     73792.000000   73792.000000    73792.000000  73792.000000    0.0  \n",
       "mean          0.113020       0.086784        0.113454     14.656467    NaN  \n",
       "std           0.481071       0.281521        0.481729     10.927544    NaN  \n",
       "min           0.000000       0.000000        0.000000      0.000000    NaN  \n",
       "25%           0.000000       0.000000        0.000000      6.000000    NaN  \n",
       "50%           0.000000       0.000000        0.000000     12.000000    NaN  \n",
       "75%           0.000000       0.000000        0.000000     21.000000    NaN  \n",
       "max           4.000000       1.000000        4.000000     51.000000    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating datasets cross the years\n",
    "data_14 = pd.read_csv('./cleaned/2014-2015.CSV')\n",
    "data_15 = pd.read_csv('./cleaned/2015-2016.CSV')\n",
    "data_16 = pd.read_csv('./cleaned/2016-2017.CSV')\n",
    "data_17 = pd.read_csv('./cleaned/2017-2018.CSV')\n",
    "data_18 = pd.read_csv('./cleaned/2018-2019.CSV')\n",
    "data_test = pd.read_csv('./cleaned/Test.CSV')\n",
    "\n",
    "col14 = data_14.columns\n",
    "col15 = data_15.columns\n",
    "col16 = data_16.columns\n",
    "col17 = data_17.columns\n",
    "col18 = data_18.columns\n",
    "test_d = data_test.columns\n",
    "all_cols = list(set(col14) | set(col15) | set(col16) |set(col17) |set(col18) |set(test_d))\n",
    "common_cols = list(set(col14) & set(col15) & set(col16) & set(col17) & set(col18) & set(test_d))\n",
    "all_contest_data = ['./cleaned/2014-2015.CSV','./cleaned/2015-2016.CSV','./cleaned/2016-2017.CSV',\n",
    "                    './cleaned/2017-2018.CSV','./cleaned/2018-2019.CSV','./cleaned/Test.CSV']\n",
    "df = pd.concat(pd.read_csv(f)[common_cols] for f in all_contest_data)\n",
    "df.columns\n",
    "df.shape\n",
    "df.to_csv('./cleaned/contest_data.csv', index = False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wheather = pd.read_csv('./cleaned/wheather.CSV',decimal=\",\")\n",
    "data_wheather['DATE_ONLY'] = pd.to_datetime(data_wheather['TIME_UTC_STR']).dt.strftime('%m/%d/%Y')\n",
    "data_wheather = data_wheather.sort_values(by=['DATE_ONLY']).drop(columns=[\"Unnamed: 8\"])\n",
    "\n",
    "data_wheather = data_wheather.assign(season_year = lambda x: x['file_loc'].str.split('\\\\').str[1])\\\n",
    "                .assign(location = lambda x: x['file_loc'].str.split('\\\\').str[2])\\\n",
    "                .assign(match_type = lambda x: x['file_loc'].str.split('\\\\').str[3])\\\n",
    "                .assign(match_name = lambda x: x['file_loc'].str.split('\\\\').str[4])\\\n",
    "                .assign(match_name = lambda x: x['match_name'].str.split('_').str[2])\\\n",
    "                .assign(match_name = lambda x: x['match_name'].str.split('.').str[0])\\\n",
    "                .drop(columns = ['file_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = {'AIR_TEMP':[('mean_air_temp','mean'),\n",
    "                ('std_air_temp','std'),\n",
    "                ('med_air_temp','median'),\n",
    "                ('max_air_temp','max'),\n",
    "                ('min_air_temp','min'),\n",
    "                ('range_air_temp',lambda x: max(x) - min(x)),\n",
    "                ('skew_air_temp','skew')],\n",
    "              'TRACK_TEMP' : [('mean_track_temp','mean'),\n",
    "                ('std_track_temp','std'),\n",
    "                ('med_track_temp','median'),\n",
    "                ('max_track_temp','max'),\n",
    "                ('min_track_temp','min'),\n",
    "                ('range_track_temp',lambda x: max(x) - min(x)),\n",
    "                ('skew_track_temp','skew')],\n",
    "                'HUMIDITY' : [('mean_HUMIDITY','mean'),\n",
    "                            ('std_HUMIDITY','std'),\n",
    "                            ('med_HUMIDITY','median'),\n",
    "                            ('max_HUMIDITY','max'),\n",
    "                            ('min_HUMIDITY','min'),\n",
    "                            ('range_HUMIDITY',lambda x: max(x) - min(x)),\n",
    "                            ('skew_HUMIDITY','skew')],\n",
    "                'PRESSURE' : [('mean_PRESSURE','mean'),\n",
    "                    ('std_PRESSURE','std'),\n",
    "                    ('med_PRESSURE','median'),\n",
    "                    ('max_PRESSURE','max'),\n",
    "                    ('min_PRESSURE','min'),\n",
    "                    ('range_PRESSURE',lambda x: max(x) - min(x)),\n",
    "                    ('skew_PRESSURE','skew')],\n",
    "\n",
    "            'WIND_SPEED' : [('mean_WIND_SPEED','mean'),\n",
    "                          ('std_WIND_SPEED','std'),\n",
    "                          ('med_WIND_SPEED','median'),\n",
    "                          ('max_WIND_SPEED','max'),\n",
    "                          ('min_WIND_SPEED','min'),\n",
    "                          ('range_WIND_SPEED',lambda x: max(x) - min(x)),\n",
    "                          ('skew_WIND_SPEED','skew'),\n",
    "                        ]\n",
    "              }\n",
    "\n",
    "# data_wheather[aggregation.keys] = data_wheather[aggregation.keys()].apply(pd.to_numeric)\n",
    "\n",
    "data_wheather['match_key'] = data_wheather['DATE_ONLY'] + data_wheather['match_name']\n",
    "df = data_wheather.groupby(['match_key','DATE_ONLY','location','season_year','match_name','match_type'], as_index=True).agg(aggregation).reset_index()\n",
    "df.columns = df.columns.droplevel()\n",
    "column_names = df.columns.values\n",
    "column_names[:6] = ['match_key','DATE_ONLY','location','season_year','match_name','match_type']\n",
    "df.columns = column_names\n",
    "df = df.drop(columns = ['match_key'])\n",
    "df.to_csv('./cleaned/weather_processed.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (1,2,9,11,24,28,29,32,34,42,44,45) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_race = pd.read_csv('./cleaned/contest_data.CSV')\n",
    "data_race = data_race.assign(season_year = lambda x: x['file_loc'].str.split('\\\\').str[0])\\\n",
    "            .assign(season_year = lambda x: x['season_year'].str.split('/').str[2])\\\n",
    "                .assign(location = lambda x: x['file_loc'].str.split('\\\\').str[1])\\\n",
    "                    .assign(match_type = lambda x: x['file_loc'].str.split('\\\\').str[2])\\\n",
    "                        .assign(match_name = lambda x: x['file_loc'].str.split('\\\\').str[3])\\\n",
    "                            .assign(match_name = lambda x: x['match_name'].str.split('_').str[2])\\\n",
    "                                .assign(match_name = lambda x: x['match_name'].str.split('.').str[0])\\\n",
    "                                    .assign(match_name = lambda x: x['match_name'].str.replace(r\"\\(.*\\)\",\"\"))\\\n",
    "                                        .drop(columns = ['file_loc'])\n",
    "data_race.to_csv('./cleaned/contest_pre-final.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KPH', 'PIT_TIME', 'DRIVER_NAME', 'S3', 'TEAM', 'S1', 'S2',\n",
       "       'LAP_NUMBER', 'CROSSING_FINISH_LINE_IN_PIT', 'GROUP', 'season_year',\n",
       "       'location', 'match_type', 'match_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_race = data_race.drop(columns = ['DRIVER_NUMBER', 'LAPS', 'FL_KPH', 'HOUR', 'MANUFACTURER', 'TOTAL_TIME',\n",
    "       'Unnamed: 25', 'NUMBER', 'DRIVER_SHORTNAME', 'S2_LARGE',\n",
    "       'FL_LAPNUM', 'VEHICLE',\n",
    "       'LAP_IMPROVEMENT', 'CLASS', 'S2_IMPROVEMENT', 'TOP_SPEED',\n",
    "       'DRIVER_COUNTRY', 'STATUS', 'ELAPSED', 'ï»¿POSITION', 'TIRES',\n",
    "       'S3_LARGE', 'GAP_PREVIOUS', 'ï»¿NUMBER',\n",
    "       'GAP_FIRST', 'DIVISION', 'DRIVER_SECONDNAME', 'DRIVER_FIRSTNAME',\n",
    "       'LAP_TIME', 'S1_IMPROVEMENT', 'DRIVER_HOMETOWN', 'FL_TIME',\n",
    "       'S1_LARGE', 'DRIVER_LICENSE', 'S3_IMPROVEMENT'])\n",
    "data_race.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\Aishwarya\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "for i in (['S1', 'S2', 'S3', 'PIT_TIME']):\n",
    "    p = data_race[i]\n",
    "    for count, i in enumerate(p):\n",
    "        x = len(str(i).split(':'))\n",
    "        if (pd.isna(i)):\n",
    "            p[count] = \"00:00:00\"\n",
    "        elif (x == 1):\n",
    "            p[count] = \"00:00:\" + str(i)\n",
    "        elif (x == 2):\n",
    "            p[count] = \"00:\" + str(i)\n",
    "        elif (x == 3):\n",
    "            p[count] = \"\" + str(i)\n",
    "        p[count] = float(p[count].split(\":\")[0])*3600000 + float(p[count].split(\":\")[1])*60000 + float(p[count].split(\":\")[2])*1000\n",
    "    data_race[i] = p\n",
    "    \n",
    "data_race[['KPH', 'S1', 'S2', 'S3', 'LAP_NUMBER', 'PIT_TIME']] = data_race[['KPH', 'S1', 'S2', 'S3', 'LAP_NUMBER', 'PIT_TIME']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = {'KPH':[('mean_KPH','mean'),\n",
    "                ('std_KPH','std'),\n",
    "                ('med_KPH','median'),\n",
    "                ('max_KPH','max'),\n",
    "                ('min_KPH','min'),\n",
    "                ('range_KPH',lambda x: max(x) - min(x)),\n",
    "                ('skew_KPH','skew')],\n",
    "              'S1' : [('mean_S1','mean'),\n",
    "                ('std_S1','std'),\n",
    "                ('med_S1','median'),\n",
    "                ('max_S1','max'),\n",
    "                ('min_S1','min'),\n",
    "                ('range_S1',lambda x: max(x) - min(x)),\n",
    "                ('skew_S1','skew')],\n",
    "              'S2' : [('mean_S2','mean'),\n",
    "                ('std_S2','std'),\n",
    "                ('med_S2','median'),\n",
    "                ('max_S2','max'),\n",
    "                ('min_S2','min'),\n",
    "                ('range_S2',lambda x: max(x) - min(x)),\n",
    "                ('skew_S2','skew')],\n",
    "              'S3' : [('mean_S3','mean'),\n",
    "                ('std_S3','std'),\n",
    "                ('med_S3','median'),\n",
    "                ('max_S3','max'),\n",
    "                ('min_S3','min'),\n",
    "                ('range_S3',lambda x: max(x) - min(x)),\n",
    "                ('skew_S3','skew')],\n",
    "               'LAP_NUMBER': [('Total_Lap_Num','max')],\n",
    "               'PIT_TIME': [('PIT_TIME_cnt','count')],\n",
    "               'CROSSING_FINISH_LINE_IN_PIT': [('cnt_CROSSING_FINISH_LINE_IN_PIT','count')],\n",
    "              }\n",
    "\n",
    "data_race['match_key'] = data_race['DRIVER_NAME'] + data_race['season_year'] + data_race['location'] + data_race['match_type'] + data_race['match_name'] \n",
    "df = data_race.groupby(['match_key','DRIVER_NAME','location','season_year','match_name','match_type','GROUP','TEAM'], as_index=True).agg(aggregation).reset_index()\n",
    "df.columns = df.columns.droplevel()\n",
    "column_names = df.columns.values\n",
    "column_names[:8] = ['match_key','DRIVER_NAME','location','season_year','match_name','match_type','GROUP',  'TEAM']\n",
    "df.columns = column_names\n",
    "df = df.drop(columns = ['match_key'])\n",
    "df = df.fillna(0)\n",
    "df.to_csv('./cleaned/race_final_processed.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((664, 74), (1908, 38))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr = pd.read_csv('./cleaned/race_final_processed.csv')\n",
    "dw = pd.read_csv('./cleaned/weather_processed.csv')\n",
    "final_data = dr.merge(dw, how = 'left', on = ['location','season_year','match_name','match_type'])\n",
    "final_data_with_weather = final_data[final_data['mean_air_temp'].notnull()]\n",
    "final_data_with_weather.shape, dr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, linear_model, neighbors, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def test_model(X, y, model_name, model):\n",
    "    print(\"MODEL: {}\".format(model_name))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model.fit(X_train, y_train)\n",
    "    Z = model.predict(X_test)\n",
    "    print(\"R2 Value: \", r2_score(Z, y_test))\n",
    "    print(\"MSE Value: \", mean_squared_error(Z, y_test))\n",
    "    \n",
    "models = {\n",
    "    \"RANSACRegressor\": linear_model.RANSACRegressor(random_state=0),\n",
    "    \"ElasticNet\": linear_model.ElasticNet(random_state=0),\n",
    "    \"Random Forest\": ensemble.RandomForestRegressor(n_estimators=1000),\n",
    "    \"K-Nearest Neighbors\": neighbors.KNeighborsRegressor(),\n",
    "    \"SVR\": svm.SVR(),\n",
    "    \"BayesianRidge\": linear_model.BayesianRidge()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRIVER_NAME</th>\n",
       "      <th>location</th>\n",
       "      <th>season_year</th>\n",
       "      <th>match_name</th>\n",
       "      <th>match_type</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>mean_KPH</th>\n",
       "      <th>std_KPH</th>\n",
       "      <th>med_KPH</th>\n",
       "      <th>max_KPH</th>\n",
       "      <th>min_KPH</th>\n",
       "      <th>range_KPH</th>\n",
       "      <th>skew_KPH</th>\n",
       "      <th>mean_S1</th>\n",
       "      <th>std_S1</th>\n",
       "      <th>med_S1</th>\n",
       "      <th>max_S1</th>\n",
       "      <th>min_S1</th>\n",
       "      <th>range_S1</th>\n",
       "      <th>skew_S1</th>\n",
       "      <th>mean_S2</th>\n",
       "      <th>std_S2</th>\n",
       "      <th>med_S2</th>\n",
       "      <th>max_S2</th>\n",
       "      <th>min_S2</th>\n",
       "      <th>range_S2</th>\n",
       "      <th>skew_S2</th>\n",
       "      <th>mean_S3</th>\n",
       "      <th>std_S3</th>\n",
       "      <th>med_S3</th>\n",
       "      <th>max_S3</th>\n",
       "      <th>min_S3</th>\n",
       "      <th>range_S3</th>\n",
       "      <th>skew_S3</th>\n",
       "      <th>Total_Lap_Num</th>\n",
       "      <th>PIT_TIME_cnt</th>\n",
       "      <th>cnt_CROSSING_FINISH_LINE_IN_PIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MA Qing Hua</td>\n",
       "      <td>Buenos</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Groups Qualifying Session</td>\n",
       "      <td>Q</td>\n",
       "      <td>4.0</td>\n",
       "      <td>TECHEETAH</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>74.034080</td>\n",
       "      <td>55.95</td>\n",
       "      <td>108.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>104.7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.205626e+06</td>\n",
       "      <td>1.673677e+06</td>\n",
       "      <td>1205626.5</td>\n",
       "      <td>2389095.0</td>\n",
       "      <td>22158.0</td>\n",
       "      <td>2366937.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28569.500000</td>\n",
       "      <td>2348.301620</td>\n",
       "      <td>28569.5</td>\n",
       "      <td>30230.0</td>\n",
       "      <td>26909.0</td>\n",
       "      <td>3321.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33244.500000</td>\n",
       "      <td>132.228968</td>\n",
       "      <td>33244.5</td>\n",
       "      <td>33338.0</td>\n",
       "      <td>33151.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MA Qing Hua</td>\n",
       "      <td>HongKong</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Groups Qualifying Session</td>\n",
       "      <td>Q</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TECHEETAH</td>\n",
       "      <td>60.720000</td>\n",
       "      <td>44.706677</td>\n",
       "      <td>83.70</td>\n",
       "      <td>103.4</td>\n",
       "      <td>9.6</td>\n",
       "      <td>93.8</td>\n",
       "      <td>-0.504993</td>\n",
       "      <td>1.454818e+05</td>\n",
       "      <td>2.776263e+05</td>\n",
       "      <td>21419.0</td>\n",
       "      <td>642077.0</td>\n",
       "      <td>18214.0</td>\n",
       "      <td>623863.0</td>\n",
       "      <td>2.235218</td>\n",
       "      <td>25340.400000</td>\n",
       "      <td>3472.268898</td>\n",
       "      <td>25310.0</td>\n",
       "      <td>30446.0</td>\n",
       "      <td>20834.0</td>\n",
       "      <td>9612.0</td>\n",
       "      <td>0.398980</td>\n",
       "      <td>100467.400000</td>\n",
       "      <td>163235.989761</td>\n",
       "      <td>27764.0</td>\n",
       "      <td>392459.0</td>\n",
       "      <td>25098.0</td>\n",
       "      <td>367361.0</td>\n",
       "      <td>2.235539</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA Qing Hua</td>\n",
       "      <td>HongKong</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Race</td>\n",
       "      <td>Race</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TECHEETAH</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.20</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.520100e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>25201.0</td>\n",
       "      <td>25201.0</td>\n",
       "      <td>25201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69831.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69831.0</td>\n",
       "      <td>69831.0</td>\n",
       "      <td>69831.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>254614.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>254614.0</td>\n",
       "      <td>254614.0</td>\n",
       "      <td>254614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MA Qing Hua</td>\n",
       "      <td>Marrakesh</td>\n",
       "      <td>2016-2017</td>\n",
       "      <td>Groups Qualifying Session</td>\n",
       "      <td>Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TECHEETAH</td>\n",
       "      <td>96.700000</td>\n",
       "      <td>21.620515</td>\n",
       "      <td>89.10</td>\n",
       "      <td>128.5</td>\n",
       "      <td>80.1</td>\n",
       "      <td>48.4</td>\n",
       "      <td>1.761566</td>\n",
       "      <td>3.075050e+04</td>\n",
       "      <td>2.285297e+04</td>\n",
       "      <td>34467.5</td>\n",
       "      <td>54067.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54067.0</td>\n",
       "      <td>-0.879319</td>\n",
       "      <td>32754.500000</td>\n",
       "      <td>22510.967172</td>\n",
       "      <td>40873.0</td>\n",
       "      <td>49272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49272.0</td>\n",
       "      <td>-1.666986</td>\n",
       "      <td>17328.750000</td>\n",
       "      <td>12946.936198</td>\n",
       "      <td>19069.5</td>\n",
       "      <td>31176.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31176.0</td>\n",
       "      <td>-0.771944</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MA Qing Hua</td>\n",
       "      <td>Newyork2</td>\n",
       "      <td>2017-2018</td>\n",
       "      <td>Qualifying 2 Group 1</td>\n",
       "      <td>Q</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NIO Formula E Team</td>\n",
       "      <td>74.933333</td>\n",
       "      <td>36.874698</td>\n",
       "      <td>93.10</td>\n",
       "      <td>99.2</td>\n",
       "      <td>32.5</td>\n",
       "      <td>66.7</td>\n",
       "      <td>-1.678880</td>\n",
       "      <td>5.431333e+04</td>\n",
       "      <td>3.739482e+04</td>\n",
       "      <td>33244.0</td>\n",
       "      <td>97489.0</td>\n",
       "      <td>32207.0</td>\n",
       "      <td>65282.0</td>\n",
       "      <td>1.730552</td>\n",
       "      <td>28552.333333</td>\n",
       "      <td>1275.374585</td>\n",
       "      <td>29261.0</td>\n",
       "      <td>29316.0</td>\n",
       "      <td>27080.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>-1.728428</td>\n",
       "      <td>27890.333333</td>\n",
       "      <td>1207.169140</td>\n",
       "      <td>27685.0</td>\n",
       "      <td>29187.0</td>\n",
       "      <td>26799.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0.743282</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DRIVER_NAME   location season_year                 match_name match_type  \\\n",
       "0   MA Qing Hua     Buenos   2016-2017  Groups Qualifying Session          Q   \n",
       "1   MA Qing Hua   HongKong   2016-2017  Groups Qualifying Session          Q   \n",
       "2   MA Qing Hua   HongKong   2016-2017                      Race        Race   \n",
       "3   MA Qing Hua  Marrakesh   2016-2017  Groups Qualifying Session          Q   \n",
       "4   MA Qing Hua   Newyork2   2017-2018       Qualifying 2 Group 1          Q   \n",
       "\n",
       "  GROUP                TEAM   mean_KPH    std_KPH  med_KPH  max_KPH  min_KPH  \\\n",
       "0   4.0           TECHEETAH  55.950000  74.034080    55.95    108.3      3.6   \n",
       "1   2.0           TECHEETAH  60.720000  44.706677    83.70    103.4      9.6   \n",
       "2   2.0           TECHEETAH  19.200000   0.000000    19.20     19.2     19.2   \n",
       "3   1.0           TECHEETAH  96.700000  21.620515    89.10    128.5     80.1   \n",
       "4   1.0  NIO Formula E Team  74.933333  36.874698    93.10     99.2     32.5   \n",
       "\n",
       "   range_KPH  skew_KPH       mean_S1        std_S1     med_S1     max_S1  \\\n",
       "0      104.7  0.000000  1.205626e+06  1.673677e+06  1205626.5  2389095.0   \n",
       "1       93.8 -0.504993  1.454818e+05  2.776263e+05    21419.0   642077.0   \n",
       "2        0.0  0.000000  2.520100e+04  0.000000e+00    25201.0    25201.0   \n",
       "3       48.4  1.761566  3.075050e+04  2.285297e+04    34467.5    54067.0   \n",
       "4       66.7 -1.678880  5.431333e+04  3.739482e+04    33244.0    97489.0   \n",
       "\n",
       "    min_S1   range_S1   skew_S1       mean_S2        std_S2   med_S2   max_S2  \\\n",
       "0  22158.0  2366937.0  0.000000  28569.500000   2348.301620  28569.5  30230.0   \n",
       "1  18214.0   623863.0  2.235218  25340.400000   3472.268898  25310.0  30446.0   \n",
       "2  25201.0        0.0  0.000000  69831.000000      0.000000  69831.0  69831.0   \n",
       "3      0.0    54067.0 -0.879319  32754.500000  22510.967172  40873.0  49272.0   \n",
       "4  32207.0    65282.0  1.730552  28552.333333   1275.374585  29261.0  29316.0   \n",
       "\n",
       "    min_S2  range_S2   skew_S2        mean_S3         std_S3    med_S3  \\\n",
       "0  26909.0    3321.0  0.000000   33244.500000     132.228968   33244.5   \n",
       "1  20834.0    9612.0  0.398980  100467.400000  163235.989761   27764.0   \n",
       "2  69831.0       0.0  0.000000  254614.000000       0.000000  254614.0   \n",
       "3      0.0   49272.0 -1.666986   17328.750000   12946.936198   19069.5   \n",
       "4  27080.0    2236.0 -1.728428   27890.333333    1207.169140   27685.0   \n",
       "\n",
       "     max_S3    min_S3  range_S3   skew_S3  Total_Lap_Num  PIT_TIME_cnt  \\\n",
       "0   33338.0   33151.0     187.0  0.000000            2.0             2   \n",
       "1  392459.0   25098.0  367361.0  2.235539            5.0             5   \n",
       "2  254614.0  254614.0       0.0  0.000000            1.0             1   \n",
       "3   31176.0       0.0   31176.0 -0.771944            4.0             4   \n",
       "4   29187.0   26799.0    2388.0  0.743282            3.0             3   \n",
       "\n",
       "   cnt_CROSSING_FINISH_LINE_IN_PIT  \n",
       "0                                0  \n",
       "1                                1  \n",
       "2                                1  \n",
       "3                                2  \n",
       "4                                0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2014-2015', '2015-2016', '2016-2017', '2017-2018', '2018-2019'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dr['season_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
