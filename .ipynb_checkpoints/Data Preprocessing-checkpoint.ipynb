{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', None)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# pd.set_option('max_colwidth',-1)\n",
    "\n",
    "\n",
    "#Collecting and concatenating all csv files per year\n",
    "path_folder = \"./sampledata/\"\n",
    "folder_list = os.listdir(\"./sampledata\")\n",
    "EXT = \"*.csv\"\n",
    "for sub in folder_list[:1]:\n",
    "    PATH = path_folder + sub\n",
    "    all_csv_files = [file \n",
    "                     for path, subdir, files in os.walk(PATH)\n",
    "                     for file in glob(os.path.join(path,EXT))\n",
    "                    ]\n",
    "    df = pd.concat((pd.read_csv(f, sep=\";\", encoding = \"ISO-8859-1\").assign(file_loc=f) for f in all_csv_files))\n",
    "\n",
    "    df = df.rename(columns=lambda x: x.strip())\n",
    "    df.to_csv('./cleaned/' + sub + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DRIVER_NUMBER', 'LAPS', 'FL_KPH', 'HOUR', 'MANUFACTURER', 'TOTAL_TIME',\n",
       "       'KPH', 'Unnamed: 25', 'NUMBER', 'DRIVER_SHORTNAME', 'S2_LARGE', 'GROUP',\n",
       "       'FL_LAPNUM', 'CROSSING_FINISH_LINE_IN_PIT', 'PIT_TIME', 'VEHICLE',\n",
       "       'TEAM', 'LAP_IMPROVEMENT', 'CLASS', 'S2_IMPROVEMENT', 'TOP_SPEED',\n",
       "       'DRIVER_COUNTRY', 'STATUS', 'ELAPSED', 'ï»¿POSITION', 'file_loc',\n",
       "       'TIRES', 'DRIVER_NAME', 'S3_LARGE', 'GAP_PREVIOUS', 'LAP_NUMBER',\n",
       "       'ï»¿NUMBER', 'S2', 'GAP_FIRST', 'DIVISION', 'DRIVER_SECONDNAME',\n",
       "       'DRIVER_FIRSTNAME', 'S3', 'S1', 'LAP_TIME', 'S1_IMPROVEMENT',\n",
       "       'DRIVER_HOMETOWN', 'FL_TIME', 'S1_LARGE', 'DRIVER_LICENSE',\n",
       "       'S3_IMPROVEMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(74012, 46)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRIVER_NUMBER</th>\n",
       "      <th>LAPS</th>\n",
       "      <th>FL_KPH</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>DRIVER_SHORTNAME</th>\n",
       "      <th>FL_LAPNUM</th>\n",
       "      <th>LAP_IMPROVEMENT</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>S2_IMPROVEMENT</th>\n",
       "      <th>TOP_SPEED</th>\n",
       "      <th>ï»¿POSITION</th>\n",
       "      <th>TIRES</th>\n",
       "      <th>LAP_NUMBER</th>\n",
       "      <th>ï»¿NUMBER</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>S1_IMPROVEMENT</th>\n",
       "      <th>DRIVER_LICENSE</th>\n",
       "      <th>S3_IMPROVEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>73792.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>67388.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.086784</td>\n",
       "      <td>30.704545</td>\n",
       "      <td>116.272350</td>\n",
       "      <td>101.683755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.650000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.259091</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.112343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.823204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.656467</td>\n",
       "      <td>24.287118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.281521</td>\n",
       "      <td>8.970727</td>\n",
       "      <td>6.986659</td>\n",
       "      <td>25.887216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.621204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.467028</td>\n",
       "      <td>0.481071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.479707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.913893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.927544</td>\n",
       "      <td>24.259728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.476026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.100000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>112.700000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>115.800000</td>\n",
       "      <td>109.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>119.900000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>130.100000</td>\n",
       "      <td>184.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DRIVER_NUMBER        LAPS      FL_KPH           KPH  Unnamed: 25  \\\n",
       "count  73792.000000   220.000000  217.000000  67388.000000  0.0           \n",
       "mean   0.086784       30.704545   116.272350  101.683755   NaN            \n",
       "std    0.281521       8.970727    6.986659    25.887216    NaN            \n",
       "min    0.000000       0.000000    102.100000  1.700000     NaN            \n",
       "25%    0.000000       29.000000   112.700000  100.200000   NaN            \n",
       "50%    0.000000       31.000000   115.800000  109.400000   NaN            \n",
       "75%    0.000000       35.000000   119.900000  116.000000   NaN            \n",
       "max    1.000000       47.000000   130.100000  184.500000   NaN            \n",
       "\n",
       "           NUMBER  DRIVER_SHORTNAME   FL_LAPNUM  LAP_IMPROVEMENT  CLASS  \\\n",
       "count  220.000000  0.0               220.000000  73792.000000     0.0     \n",
       "mean   29.650000  NaN                23.259091   0.113020        NaN      \n",
       "std    29.621204  NaN                8.467028    0.481071        NaN      \n",
       "min    2.000000   NaN                0.000000    0.000000        NaN      \n",
       "25%    7.750000   NaN                20.000000   0.000000        NaN      \n",
       "50%    19.500000  NaN                25.000000   0.000000        NaN      \n",
       "75%    36.250000  NaN                29.000000   0.000000        NaN      \n",
       "max    99.000000  NaN                47.000000   4.000000        NaN      \n",
       "\n",
       "       S2_IMPROVEMENT  TOP_SPEED  ï»¿POSITION  TIRES    LAP_NUMBER  \\\n",
       "count  73792.000000    0.0        181.000000   0.0    73792.000000   \n",
       "mean   0.112343       NaN         8.823204    NaN     14.656467      \n",
       "std    0.479707       NaN         4.913893    NaN     10.927544      \n",
       "min    0.000000       NaN         1.000000    NaN     0.000000       \n",
       "25%    0.000000       NaN         5.000000    NaN     6.000000       \n",
       "50%    0.000000       NaN         9.000000    NaN     12.000000      \n",
       "75%    0.000000       NaN         13.000000   NaN     21.000000      \n",
       "max    4.000000       NaN         19.000000   NaN     51.000000      \n",
       "\n",
       "          ï»¿NUMBER  DIVISION  S1_IMPROVEMENT  DRIVER_LICENSE  S3_IMPROVEMENT  \n",
       "count  73792.000000  0.0       73792.000000    0.0             73792.000000    \n",
       "mean   24.287118    NaN        0.110432       NaN              0.113454        \n",
       "std    24.259728    NaN        0.476026       NaN              0.481729        \n",
       "min    1.000000     NaN        0.000000       NaN              0.000000        \n",
       "25%    7.000000     NaN        0.000000       NaN              0.000000        \n",
       "50%    19.000000    NaN        0.000000       NaN              0.000000        \n",
       "75%    28.000000    NaN        0.000000       NaN              0.000000        \n",
       "max    99.000000    NaN        4.000000       NaN              4.000000        "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Concatenating datasets cross the years\n",
    "data_14 = pd.read_csv('./cleaned/2014-2015.CSV')\n",
    "data_15 = pd.read_csv('./cleaned/2015-2016.CSV')\n",
    "data_16 = pd.read_csv('./cleaned/2016-2017.CSV')\n",
    "data_17 = pd.read_csv('./cleaned/2017-2018.CSV')\n",
    "data_18 = pd.read_csv('./cleaned/2018-2019.CSV')\n",
    "data_test = pd.read_csv('./cleaned/Test.CSV')\n",
    "\n",
    "col14 = data_14.columns\n",
    "col15 = data_15.columns\n",
    "col16 = data_16.columns\n",
    "col17 = data_17.columns\n",
    "col18 = data_18.columns\n",
    "test_d = data_test.columns\n",
    "all_cols = list(set(col14) | set(col15) | set(col16) |set(col17) |set(col18) |set(test_d))\n",
    "common_cols = list(set(col14) & set(col15) & set(col16) & set(col17) & set(col18) & set(test_d))\n",
    "all_contest_data = ['./cleaned/2014-2015.CSV','./cleaned/2015-2016.CSV','./cleaned/2016-2017.CSV',\n",
    "                    './cleaned/2017-2018.CSV','./cleaned/2018-2019.CSV','./cleaned/Test.CSV']\n",
    "df = pd.concat(pd.read_csv(f)[common_cols] for f in all_contest_data)\n",
    "df.columns\n",
    "df.shape\n",
    "df.to_csv('./cleaned/contest_data.csv', index = False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wheather = pd.read_csv('./cleaned/wheather.CSV',decimal=\",\")\n",
    "data_wheather['DATE_ONLY'] = pd.to_datetime(data_wheather['TIME_UTC_STR']).dt.strftime('%m/%d/%Y')\n",
    "data_wheather = data_wheather.sort_values(by=['DATE_ONLY']).drop(columns=[\"Unnamed: 8\"])\n",
    "\n",
    "data_wheather = data_wheather.assign(season_year = lambda x: x['file_loc'].str.split('\\\\').str[1])\\\n",
    "                .assign(location = lambda x: x['file_loc'].str.split('\\\\').str[2])\\\n",
    "                .assign(match_type = lambda x: x['file_loc'].str.split('\\\\').str[3])\\\n",
    "                .assign(match_name = lambda x: x['file_loc'].str.split('\\\\').str[4])\\\n",
    "                .assign(match_name = lambda x: x['match_name'].str.split('_').str[2])\\\n",
    "                .assign(match_name = lambda x: x['match_name'].str.split('.').str[0])\\\n",
    "                .drop(columns = ['file_loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = {'AIR_TEMP':[('mean_air_temp','mean'),\n",
    "                ('std_air_temp','std'),\n",
    "                ('med_air_temp','median'),\n",
    "                ('max_air_temp','max'),\n",
    "                ('min_air_temp','min'),\n",
    "                ('range_air_temp',lambda x: max(x) - min(x)),\n",
    "                ('skew_air_temp','skew')],\n",
    "              'TRACK_TEMP' : [('mean_track_temp','mean'),\n",
    "                ('std_track_temp','std'),\n",
    "                ('med_track_temp','median'),\n",
    "                ('max_track_temp','max'),\n",
    "                ('min_track_temp','min'),\n",
    "                ('range_track_temp',lambda x: max(x) - min(x)),\n",
    "                ('skew_track_temp','skew')],\n",
    "                'HUMIDITY' : [('mean_HUMIDITY','mean'),\n",
    "                            ('std_HUMIDITY','std'),\n",
    "                            ('med_HUMIDITY','median'),\n",
    "                            ('max_HUMIDITY','max'),\n",
    "                            ('min_HUMIDITY','min'),\n",
    "                            ('range_HUMIDITY',lambda x: max(x) - min(x)),\n",
    "                            ('skew_HUMIDITY','skew')],\n",
    "                'PRESSURE' : [('mean_PRESSURE','mean'),\n",
    "                    ('std_PRESSURE','std'),\n",
    "                    ('med_PRESSURE','median'),\n",
    "                    ('max_PRESSURE','max'),\n",
    "                    ('min_PRESSURE','min'),\n",
    "                    ('range_PRESSURE',lambda x: max(x) - min(x)),\n",
    "                    ('skew_PRESSURE','skew')],\n",
    "\n",
    "            'WIND_SPEED' : [('mean_WIND_SPEED','mean'),\n",
    "                          ('std_WIND_SPEED','std'),\n",
    "                          ('med_WIND_SPEED','median'),\n",
    "                          ('max_WIND_SPEED','max'),\n",
    "                          ('min_WIND_SPEED','min'),\n",
    "                          ('range_WIND_SPEED',lambda x: max(x) - min(x)),\n",
    "                          ('skew_WIND_SPEED','skew'),\n",
    "                        ]\n",
    "              }\n",
    "\n",
    "data_wheather[aggregation.keys] = data_wheather[aggregation.keys()].apply(pd.to_numeric)\n",
    "\n",
    "data_wheather['match_key'] = data_wheather['DATE_ONLY'] + data_wheather['match_name']\n",
    "df = data_wheather.groupby(['match_key','DATE_ONLY','location','season_year','match_name','match_type'], as_index=True).agg(aggregation).reset_index()\n",
    "df.columns = df.columns.droplevel()\n",
    "column_names = df.columns.values\n",
    "column_names[:6] = ['match_key','DATE_ONLY','location','season_year','match_name','match_type']\n",
    "df.columns = column_names\n",
    "df = df.drop(columns = ['match_key'])\n",
    "df.to_csv('./cleaned/weather_processed.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sai\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (4,5,11,15,21,22,29,33,35,36,41,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data_race = pd.read_csv('./cleaned/contest_data.CSV')\n",
    "data_race = data_race.assign(season_year = lambda x: x['file_loc'].str.split('\\\\').str[0])\\\n",
    "            .assign(season_year = lambda x: x['season_year'].str.split('/').str[2])\\\n",
    "                .assign(location = lambda x: x['file_loc'].str.split('\\\\').str[1])\\\n",
    "                    .assign(match_type = lambda x: x['file_loc'].str.split('\\\\').str[2])\\\n",
    "                        .assign(match_name = lambda x: x['file_loc'].str.split('\\\\').str[3])\\\n",
    "                            .assign(match_name = lambda x: x['match_name'].str.split('_').str[2])\\\n",
    "                                .assign(match_name = lambda x: x['match_name'].str.split('.').str[0])\\\n",
    "                                    .assign(match_name = lambda x: x['match_name'].str.replace(r\"\\(.*\\)\",\"\"))\\\n",
    "                                        .drop(columns = ['file_loc'])\n",
    "data_race.to_csv('./cleaned/contest_pre-final.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['KPH', 'GROUP', 'CROSSING_FINISH_LINE_IN_PIT', 'PIT_TIME', 'TEAM',\n",
       "       'DRIVER_NAME', 'LAP_NUMBER', 'S2', 'S3', 'S1', 'season_year',\n",
       "       'location', 'match_type', 'match_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_race = data_race.drop(columns = ['DRIVER_NUMBER', 'LAPS', 'FL_KPH', 'HOUR', 'MANUFACTURER', 'TOTAL_TIME',\n",
    "       'Unnamed: 25', 'NUMBER', 'DRIVER_SHORTNAME', 'S2_LARGE',\n",
    "       'FL_LAPNUM', 'VEHICLE',\n",
    "       'LAP_IMPROVEMENT', 'CLASS', 'S2_IMPROVEMENT', 'TOP_SPEED',\n",
    "       'DRIVER_COUNTRY', 'STATUS', 'ELAPSED', 'ï»¿POSITION', 'TIRES',\n",
    "       'S3_LARGE', 'GAP_PREVIOUS', 'ï»¿NUMBER',\n",
    "       'GAP_FIRST', 'DIVISION', 'DRIVER_SECONDNAME', 'DRIVER_FIRSTNAME',\n",
    "       'LAP_TIME', 'S1_IMPROVEMENT', 'DRIVER_HOMETOWN', 'FL_TIME',\n",
    "       'S1_LARGE', 'DRIVER_LICENSE', 'S3_IMPROVEMENT'])\n",
    "data_race.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for i in (['S1', 'S2', 'S3', 'PIT_TIME']):\n",
    "    p = data_race[i]\n",
    "    for count, i in enumerate(p):\n",
    "        x = len(str(i).split(':'))\n",
    "        if (pd.isna(i)):\n",
    "            p[count] = \"00:00:00\"\n",
    "        elif (x == 1):\n",
    "            p[count] = \"00:00:\" + str(i)\n",
    "        elif (x == 2):\n",
    "            p[count] = \"00:\" + str(i)\n",
    "        elif (x == 3):\n",
    "            p[count] = \"\" + str(i)\n",
    "        p[count] = float(p[count].split(\":\")[0])*3600000 + float(p[count].split(\":\")[1])*60000 + float(p[count].split(\":\")[2])*1000\n",
    "    data_race[i] = p\n",
    "    \n",
    "data_race[['KPH', 'S1', 'S2', 'S3', 'LAP_NUMBER', 'PIT_TIME']] = data_race[['KPH', 'S1', 'S2', 'S3', 'LAP_NUMBER', 'PIT_TIME']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = {'KPH':[('mean_KPH','mean'),\n",
    "                ('std_KPH','std'),\n",
    "                ('med_KPH','median'),\n",
    "                ('max_KPH','max'),\n",
    "                ('min_KPH','min'),\n",
    "                ('range_KPH',lambda x: max(x) - min(x)),\n",
    "                ('skew_KPH','skew')],\n",
    "              'S1' : [('mean_S1','mean'),\n",
    "                ('std_S1','std'),\n",
    "                ('med_S1','median'),\n",
    "                ('max_S1','max'),\n",
    "                ('min_S1','min'),\n",
    "                ('range_S1',lambda x: max(x) - min(x)),\n",
    "                ('skew_S1','skew')],\n",
    "              'S2' : [('mean_S2','mean'),\n",
    "                ('std_S2','std'),\n",
    "                ('med_S2','median'),\n",
    "                ('max_S2','max'),\n",
    "                ('min_S2','min'),\n",
    "                ('range_S2',lambda x: max(x) - min(x)),\n",
    "                ('skew_S2','skew')],\n",
    "              'S3' : [('mean_S3','mean'),\n",
    "                ('std_S3','std'),\n",
    "                ('med_S3','median'),\n",
    "                ('max_S3','max'),\n",
    "                ('min_S3','min'),\n",
    "                ('range_S3',lambda x: max(x) - min(x)),\n",
    "                ('skew_S3','skew')],\n",
    "               'LAP_NUMBER': [('Total_Lap_Num','max')],\n",
    "               'PIT_TIME': [('PIT_TIME_cnt','count')],\n",
    "               'CROSSING_FINISH_LINE_IN_PIT': [('cnt_CROSSING_FINISH_LINE_IN_PIT','count')],\n",
    "              }\n",
    "\n",
    "data_race['match_key'] = data_race['DRIVER_NAME'] + data_race['season_year'] + data_race['location'] + data_race['match_type'] + data_race['match_name'] \n",
    "df = data_race.groupby(['match_key','DRIVER_NAME','location','season_year','match_name','match_type','GROUP','TEAM'], as_index=True).agg(aggregation).reset_index()\n",
    "df.columns = df.columns.droplevel()\n",
    "column_names = df.columns.values\n",
    "column_names[:8] = ['match_key','DRIVER_NAME','location','season_year','match_name','match_type','GROUP',  'TEAM']\n",
    "df.columns = column_names\n",
    "df = df.drop(columns = ['match_key'])\n",
    "df = df.fillna(0)\n",
    "df.to_csv('./cleaned/race_final_processed.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((664, 74), (1908, 38))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr = pd.read_csv('./cleaned/race_final_processed.csv')\n",
    "dw = pd.read_csv('./cleaned/weather_processed.csv')\n",
    "final_data = dr.merge(dw, how = 'left', on = ['location','season_year','match_name','match_type'])\n",
    "final_data_with_weather = final_data[final_data['mean_air_temp'].notnull()]\n",
    "final_data_with_weather.shape, dr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, linear_model, neighbors, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def test_model(X, y, model_name, model):\n",
    "    print(\"MODEL: {}\".format(model_name))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model.fit(X_train, y_train)\n",
    "    Z = model.predict(X_test)\n",
    "    print(\"R2 Value: \", r2_score(Z, y_test))\n",
    "    print(\"MSE Value: \", mean_squared_error(Z, y_test))\n",
    "    \n",
    "models = {\n",
    "    \"RANSACRegressor\": linear_model.RANSACRegressor(random_state=0),\n",
    "    \"ElasticNet\": linear_model.ElasticNet(random_state=0),\n",
    "    \"Random Forest\": ensemble.RandomForestRegressor(n_estimators=1000),\n",
    "    \"K-Nearest Neighbors\": neighbors.KNeighborsRegressor(),\n",
    "    \"SVR\": svm.SVR(),\n",
    "    \"BayesianRidge\": linear_model.BayesianRidge()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
